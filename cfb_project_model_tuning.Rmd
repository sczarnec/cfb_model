---
title: "CFB Game Predictive Model"
author: "The Five Horsemen"
date: "2024-10-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Install Packages
```{r, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(rsample)
library(mice)
library(fastDummies)
library(xgboost)
library(Metrics)
library(caret)
```

## Load Data
```{r}
cfb_data = read.csv("G:/Shared drives/Machine Learning/cfb_project_data_prep_file.csv")[,-1]

betting_lines = read.csv("G:/Shared drives/Machine Learning/betting_lines_file.csv")[,-1]
```



## Light Wrangling
```{r}

# df with only rows with both fbs team
# also, let's filter out 
fbs_only = cfb_data %>% 
  filter(t1_division == "fbs" & t2_division == "fbs") %>% 
  select(-c(t1_division, t2_division)) 
  

# treat NAs
model_prepped_orig = fbs_only %>% 
  filter(completed == TRUE) %>% # get rid of non-played games
  select(-c(completed)) %>% # get rid of completed column
  filter(!is.na(t1_rol_pa_pg_l3) & !is.na(t2_rol_pa_pg_l3)) %>% # get rid of games w/o previous game info data
  
  # replace NAs from pbp with lag for each team/season window, both for t1 and t2
  # best estimate of these stats, if available
  group_by(season, t1_team) %>%
  arrange(t1_team, season, week) %>% 
  mutate(across(starts_with("t1"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup() %>% 
  group_by(season, t2_team) %>% 
  arrange(t2_team, season, week) %>% 
  mutate(across(starts_with("t2"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup()

# df with future games only
future_games = fbs_only %>% 
  filter(completed == FALSE) %>% 
  select(-c(completed))



# filter for reg season?

```


## NA Check
```{r}

# Calculate the percentage of NAs in each column
na_rate <- colMeans(is.na(model_prepped_orig))

# Create a new data frame with the NA percentages
df_na_percentage <- data.frame(
  column = colnames(model_prepped_orig),
  na_rate = na_rate
)

# display
df_na_percentage %>% 
  arrange(desc(na_rate))
```

```{r}



# omit NA cols (only a couple thousand)
model_prepped_omit = na.omit(model_prepped_orig)


# get rid of some cols for now
# will add response vars and descriptive stuff later so we can merge back to our results
response_holder = model_prepped_omit %>% 
  select(c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team))
model_prepped_omit = model_prepped_omit %>% 
  select(-c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team))



# create new df
model_prepped = model_prepped_omit %>% 
  dummy_cols('t1_conference') %>%  # conf dummies
  dummy_cols('t2_conference') %>% 
  select(-c(t1_conference, t2_conference, season_type, t1_points, t2_points)) %>% # useless cols
  mutate(neutral_site = ifelse(neutral_site == TRUE, 1, 0)) %>% # create binary from boolean
  mutate(conference_game = ifelse(conference_game == TRUE, 1, 0))
model_prepped$season = response_holder$season # add back response vars + descriptive stuff
model_prepped$week = response_holder$week
model_prepped$t1_team = response_holder$t1_team 
model_prepped$t2_team = response_holder$t2_team
model_prepped$t1_point_diff = response_holder$t1_point_diff
model_prepped$total_points = response_holder$total_points
model_prepped$t1_win = response_holder$t1_win




  

  

```


## Last Check of NAs
```{r}

# Calculate the percentage of NAs in each column
na_rate <- colMeans(is.na(model_prepped))

# Create a new data frame with the NA percentages
df_na_percentage <- data.frame(
  column = colnames(model_prepped),
  na_rate = na_rate
)

# display
df_na_percentage %>% 
  arrange(desc(na_rate))
```


## Separate Train and Test Data

```{r}

# Split the data by game_id (we want both rows of each game in same training/test sets)
set.seed(792)
split = group_initial_split(model_prepped, group = game_id, prop = 0.7)

# Extract training and test sets
train_orig = training(split) 

train = train_orig %>% 
  select(-c(game_id))



test_orig = testing(split)

test = test_orig %>% 
  select(-c(game_id))

# Check the dimensions of the resulting datasets
dim(train)
dim(test)
```



## Prepare Data for XGBoost
```{r}

# Point Diff

# Create training matrix
pd_train_matrix = xgb.DMatrix(data = as.matrix(train[,1:109]), 
                              label = as.numeric(train$t1_point_diff))

# Create training matrix
pd_test_matrix = xgb.DMatrix(data = as.matrix(test[,1:109]), 
                              label = as.numeric(test$t1_point_diff))




# Total Points

# Create training matrix
pd_train_matrix2 = xgb.DMatrix(data = as.matrix(train[,1:109]), 
                              label = as.numeric(train$total_points))

# Create training matrix
pd_test_matrix2 = xgb.DMatrix(data = as.matrix(test[,1:109]), 
                              label = as.numeric(test$total_points))
```


## Create first model

```{r}

set.seed(596)

bst_1 <- xgboost(data = pd_train_matrix, # Set training data

               

               nrounds = 100, # Set number of rounds

               

               verbose = 1, # 1 - Prints out fit

                print_every_n = 20# Prints out result every 20th iteration

 )
```
```{r}

boost_preds_1 <- predict(bst_1, pd_test_matrix) # Create predictions for xgboost model

pred_dat <- cbind.data.frame(boost_preds_1 , test$t1_point_diff)

rmse(test$t1_point_diff, boost_preds_1)


pred_dat

```
```{r}

pred_dat_win = pred_dat %>% 
  mutate(actual_win = ifelse(`test$t1_point_diff` > 0, 1, 0)) %>% 
  mutate(pred_win = ifelse(boost_preds_1 > 0, 1, 0))


# Create confusion matrix
conf_matrix <- confusionMatrix(as.factor(pred_dat_win$pred_win),
                                     as.factor(pred_dat_win$actual_win))

# Print confusion matrix and sensitivity
print(conf_matrix)

```



Now, let's tune our model. Let's start with iterations. We'll start with slow learning rate for complex problem

```{r}
# Use xgb.cv to run cross-validation inside xgboost
set.seed(596)
bst <- xgb.cv(data = pd_train_matrix, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
               
               eta = 0.005, # Set learning rate
              
               nrounds = 20000, # Set number of rounds
               early_stopping_rounds = 800, # Set number of rounds to stop at if there is no improvement
               
               verbose = 1, # 1 - Prints out fit
               nthread = 1, # Set number of parallel threads
               print_every_n = 20, # Prints out result every 20th iteration
              
               
               eval_metric = "rmse",
               ) # Set evaluation metric to use
```


nrounds = 1434, let's keep our nrounds kinda high


Max Depth and Min Child Weight Next:

```{r}
# Be Careful - This can take a very long time to run
max_depth_vals <- c(3, 5, 7, 10, 15) # Create vector of max depth values
min_child_weight <- c(1,3,5,7, 10, 15) # Create vector of min child values

# Expand grid of parameter values
cv_params <- expand.grid(max_depth_vals, min_child_weight)
names(cv_params) <- c("max_depth", "min_child_weight")
# Create results vector
error_vec  <- rep(NA, nrow(cv_params)) 
# Loop through results
for(i in 1:nrow(cv_params)){
  set.seed(596)
  bst_tune <- xgb.cv(data = pd_train_matrix, # Set training data
                     
                     nfold = 5, # Use 5 fold cross-validation
                     
                     
                     eta = 0.005, # Set learning rate
                     
                    
                     max.depth = cv_params$max_depth[i], # Set max depth
                     min_child_weight = cv_params$min_child_weight[i], # Set minimum number of samples in node to split
                     
                     
                     nrounds = 3000, # Set number of rounds
                     early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
                     
                     verbose = 1, # 1 - Prints oSut fit
                     nthread = 1, # Set number of parallel threads
                     print_every_n = 20, # Prints out result every 20th iteration,
                     
                     
                     eval_metric = "rmse" 
                     
  ) # Set evaluation metric to use
  
  error_vec[i] <- bst_tune$evaluation_log$test_rmse_mean[bst_tune$best_ntreelimit]
  
  
}

bst_tune$evaluation_log


# Join results in dataset
res_db <- cbind.data.frame(cv_params, error_vec)
names(res_db)[3] <- c("error") 
res_db$max_depth <- as.factor(res_db$max_depth) # Convert tree number to factor for plotting
res_db$min_child_weight <- as.factor(res_db$min_child_weight) # Convert node size to factor for plotting
# Print AUC heatmap
g_2 <- ggplot(res_db, aes(y = max_depth, x = min_child_weight, fill = error)) + # set aesthetics
  geom_tile() + # Use geom_tile for heatmap
  theme_bw() + # Set theme
  scale_fill_gradient2(low = "blue", # Choose low color
                       mid = "white", # Choose mid color
                       high = "red", # Choose high color
                       midpoint =mean(res_db$error), # Choose mid point
                       space = "Lab", 
                       na.value ="grey", # Choose NA value
                       guide = "colourbar", # Set color bar
                       aesthetics = "fill") + # Select aesthetics to apply
  labs(x = "Minimum Child Weight", y = "Max Depth", fill = "error") # Set labels
g_2 # Generate plot



```

Definitely 3 Depth, Will try different Child Weights but like 5, 7, or 10

Gamma Tuning

```{r, results='hide', echo=TRUE}
###### 2 - Gamma Tuning ######


gamma_vals <- c(0, 0.05, 0.1, 0.15, 0.2) # Create vector of gamma values

# Be Careful - This can take a very long time to run
set.seed(844)
error_vec  <- rep(NA, length(gamma_vals))
for(i in 1:length(gamma_vals)){
  bst_tune <- xgb.cv(data = pd_train_matrix, # Set training data
                     
                     nfold = 5, # Use 5 fold cross-validation
                     
                     eta = 0.005, # Set learning rate
                     
                     max.depth = 3, # Set max depth
                     min_child_weight = 7, # Set minimum number of samples in node to split
                     gamma = gamma_vals[i], # Set minimum loss reduction for split
                     
                     
                     
                     nrounds = 3000, # Set number of rounds
                     early_stopping_rounds = 1000, # Prints out result every 20th iteration,
                     
                     eval_metric = "rmse",
                     
                     verbose = 1, # 1 - Prints out fit
                     nthread = 1, # Set number of parallel threads
                     print_every_n = 20 # Prints out result every 20th iteration
  ) # Set evaluation metric to use
  
  
  error_vec[i] <- bst_tune$evaluation_log$test_rmse_mean[bst_tune$best_ntreelimit]
  
}
  
```

```{r}

# Lets view our results to identify the value of gamma to use:

# Gamma results
# Join gamma to values
cbind.data.frame(gamma_vals, error_vec)

```

.05 and .15 close, going with .05

Re-calibrate optimal rounds

```{r}
# Use xgb.cv to run cross-validation inside xgboost
set.seed(844)
bst <- xgb.cv(data = pd_train_matrix, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
               
              eta = 0.005, # Set learning rate
                     
              max.depth = 7, # Set max depth
              min_child_weight = 3, # Set minimum number of samples in node to split
              gamma = 0, # Set minimum loss reduction for split
             
               
              nrounds = 3000, # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
               
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
               
              eval_metric = "rmse") # Set evaluation metric to use
```

Let's increase rounda a lot for our tuning, numbers getting high

Next, let's tune ETA (learning rate).

```{r eta tuning}

# haven't tuned the other stuff yet, comment out for now

#Let's try out different ETAs

# Use xgb.cv to run cross-validation inside xgboost
set.seed(844)
bst_mod_1 <- xgb.cv(data = pd_train_matrix, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
               
              eta = 0.3, # Set learning rate
                     
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
               
              nrounds = 100000, # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
               
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
              
              eval_metric = "rmse") # Set evaluation metric to use


set.seed(844)
bst_mod_2 <- xgb.cv(data = pd_train_matrix, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
               
              eta = 0.1, # Set learning rate
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
               
              nrounds = 100000, # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
               
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
              
              eval_metric = "rmse") # Set evaluation metric to use
set.seed(844)
bst_mod_3 <- xgb.cv(data = pd_train_matrix, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
               
              eta = 0.05, # Set learning rate
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
               
              nrounds = 100000, # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
                
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
              
              eval_metric = "rmse") # Set evaluation metric to use
set.seed(844)
bst_mod_4 <- xgb.cv(data = pd_train_matrix, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
              
              eta = .01,
               
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
               
              nrounds = 100000, # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
                
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
              
              eval_metric = "rmse") # Set evaluation metric to use

set.seed(844)
bst_mod_5 <- xgb.cv(data = pd_train_matrix, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
               
              eta = 0.005, # Set learning rate
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
               
              nrounds = 100000, # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
               
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
               
              eval_metric = "rmse") # Set evaluation metric to use
```


```{r}

# eta plots

# Extract results for model with eta = 0.3
pd1 <- cbind.data.frame(bst_mod_1$evaluation_log[,c("iter", "test_rmse_mean")], rep(0.3, nrow(bst_mod_1$evaluation_log)))
names(pd1)[3] <- "eta"
# Extract results for model with eta = 0.1
pd2 <- cbind.data.frame(bst_mod_2$evaluation_log[,c("iter", "test_rmse_mean")], rep(0.1, nrow(bst_mod_2$evaluation_log)))
names(pd2)[3] <- "eta"
# Extract results for model with eta = 0.05
pd3 <- cbind.data.frame(bst_mod_3$evaluation_log[,c("iter", "test_rmse_mean")], rep(0.05, nrow(bst_mod_3$evaluation_log)))
names(pd3)[3] <- "eta"
# Extract results for model with eta = 0.01
pd4 <- cbind.data.frame(bst_mod_4$evaluation_log[,c("iter", "test_rmse_mean")], rep(0.01, nrow(bst_mod_4$evaluation_log)))
names(pd4)[3] <- "eta"
# Extract results for model with eta = 0.005
pd5 <- cbind.data.frame(bst_mod_5$evaluation_log[,c("iter", "test_rmse_mean")], rep(0.005, nrow(bst_mod_5$evaluation_log)))
names(pd5)[3] <- "eta"
# Join datasets
plot_data <- rbind.data.frame(pd1, pd2, pd3, pd4, pd5)
# Converty ETA to factor
plot_data$eta <- as.factor(plot_data$eta)
# Plot points
g_6 <- ggplot(plot_data, aes(x = iter, y = test_rmse_mean, color = eta))+
  geom_point(alpha = 0.5) +
  theme_bw() + # Set theme
  theme(panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank()) + # Remove grid 
  labs(x = "Number of Trees", title = "Error Rate v Number of Trees",
       y = "Error Rate", color = "Learning \n Rate")  # Set labels
g_6

# Plot lines
g_7 <- ggplot(plot_data, aes(x = iter, y = test_rmse_mean, color = eta))+
  geom_smooth(alpha = 0.5) +
  theme_bw() + # Set theme
  theme(panel.grid.major = element_blank(), # Remove grid
        panel.grid.minor = element_blank(), # Remove grid
        panel.border = element_blank(), # Remove grid
        panel.background = element_blank()) + # Remove grid 
  labs(x = "Number of Trees", title = "Error Rate v Number of Trees",
       y = "Error Rate", color = "Learning \n Rate")  # Set labels
g_7

```

ETA = .005

Finally, let's re-tune our optimal iterations.

```{r}
# Use xgb.cv to run cross-validation inside xgboost
set.seed(844)
bst <- xgb.cv(data = pd_train_matrix, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
               
              
              eta = 0.005, # Set learning rate
                     
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
                     #.15
                     
                     
              nrounds = 100000, # Set number of rounds
              early_stopping_rounds = 1000, # Prints out result every 20th iteration,
                     
            
              
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
               
              eval_metric = "rmse") # Set evaluation metric to use
```

nrounds = 3507

At last, let's try our optimal model (tried some different Child Weights and .05/.15 Gamma, 5 and .05 gave best results).

```{r}
set.seed(844)
bst_final <- xgboost(data = pd_train_matrix, # Set training data
              
        
               
              eta = 0.005, # Set learning rate
                     
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
               
              nrounds = 3507 , # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
               
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
              
              eval_metric = "rmse") # Set evaluation metric to use



```

```{r}

boost_preds_final <- predict(bst_final, pd_test_matrix) # Create predictions for xgboost model

pred_dat_final <- cbind.data.frame(boost_preds_final, test$t1_point_diff)

rmse(test$t1_point_diff, boost_preds_final)


pred_dat_final

```

```{r}

pred_dat_win_final = pred_dat_final %>% 
  mutate(actual_win = ifelse(`test$t1_point_diff` > 0, 1, 0)) %>% 
  mutate(pred_win = ifelse(boost_preds_final > 0, 1, 0))


# Create confusion matrix
conf_matrix_final <- confusionMatrix(as.factor(pred_dat_win_final$pred_win),
                                     as.factor(pred_dat_win_final$actual_win), positive = "1")

# Print confusion matrix and sensitivity
print(conf_matrix_final)

```


```{r}
plot_dat <- cbind.data.frame(test$t1_point_diff,boost_preds_final )
names(plot_dat) <- c("actual", "predicted")

ggplot(plot_dat, aes(x = actual, y = predicted)) +
  geom_point() +
  geom_smooth()
```

```{r}
# Extract importance
imp_mat <- xgb.importance(model = bst_final)
# Plot importance (top 10 variables)
xgb.plot.importance(imp_mat, top_n = 10)
```






