---
title: "CFB Game Predictive Model"
author: "The Five Horsemen"
date: "2024-10-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Install Packages
```{r}
library(tidyverse)
library(ggplot2)
library(rsample)
library(mice)
library(fastDummies)
library(xgboost)
library(Metrics)
library(caret)
```

<br>

# *CFB Data Data Prep*

### Load Data

```{r, warning=FALSE}

# model data
cfb_data = read.csv("G:/Shared drives/Machine Learning/Final Project Deliverables/cfb_project_data_prep_file.csv")[,-1]

# betting info for comparisons
betting_lines = read.csv("G:/Shared drives/Machine Learning/Final Project Deliverables/betting_lines_file.csv")[,-1]
```


### Initial Wrangling

```{r}

# df with only rows with both fbs team (fcs data incomplete, easier to exclude these)
# also, let's filter out 
fbs_only = cfb_data %>% 
  filter(t1_division == "fbs" & t2_division == "fbs") %>% 
  select(-c(t1_division, t2_division)) 
  

# treat NAs
model_prepped_orig = fbs_only %>% 
  filter(completed == TRUE) %>% # get rid of non-played games
  select(-c(completed)) %>% # get rid of completed column
  filter(!is.na(t1_rol_pa_pg_l3) & !is.na(t2_rol_pa_pg_l3)) %>% # get rid of games w/o previous game info data
  
  # replace NAs from pbp with lag for each team/season window, both for t1 and t2
  # best estimate of these stats, if available
  group_by(season, t1_team) %>%
  arrange(t1_team, season, week) %>% 
  mutate(across(starts_with("t1"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup() %>% 
  group_by(season, t2_team) %>% 
  arrange(t2_team, season, week) %>% 
  mutate(across(starts_with("t2"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup()

# df with future games only
future_games = fbs_only %>% 
  filter(completed == FALSE) %>% 
  select(-c(completed))


```


### NA Check
```{r}

# Calculate the percentage of NAs in each column
na_rate <- colMeans(is.na(model_prepped_orig))

# Create a new data frame with the NA percentages
df_na_percentage <- data.frame(
  column = colnames(model_prepped_orig),
  na_rate = na_rate
)

# display
df_na_percentage %>% 
  arrange(desc(na_rate))
```

```{r}

# omit NA cols (only one thousand)
model_prepped_omit = na.omit(model_prepped_orig)


# get rid of some cols for now
# will add response vars and descriptive stuff later so we can merge back to our results
response_holder = model_prepped_omit %>% 
  select(c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team))
model_prepped_omit = model_prepped_omit %>% 
  select(-c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team))



# create new df
model_prepped = model_prepped_omit %>% 
  dummy_cols('t1_conference') %>%  # conf dummies
  dummy_cols('t2_conference') %>% 
  select(-c(t1_conference, t2_conference, season_type, t1_points, t2_points)) %>% # useless cols
  mutate(neutral_site = ifelse(neutral_site == TRUE, 1, 0)) %>% # create binary from boolean
  mutate(conference_game = ifelse(conference_game == TRUE, 1, 0))
model_prepped$season = response_holder$season # add back response vars + descriptive stuff
model_prepped$week = response_holder$week
model_prepped$t1_team = response_holder$t1_team 
model_prepped$t2_team = response_holder$t2_team
model_prepped$t1_point_diff = response_holder$t1_point_diff
model_prepped$total_points = response_holder$total_points
model_prepped$t1_win = response_holder$t1_win


```


### Last Check of NAs
```{r}

# Calculate the percentage of NAs in each column
na_rate <- colMeans(is.na(model_prepped))

# Create a new data frame with the NA percentages
df_na_percentage <- data.frame(
  column = colnames(model_prepped),
  na_rate = na_rate
)

# display
df_na_percentage %>% 
  arrange(desc(na_rate))
```


### Separate Train and Test Data

```{r}

# Split the data by game_id (we want both rows of each game in same training/test sets)
set.seed(792)
split = group_initial_split(model_prepped, group = game_id, prop = 0.7)

# Extract training and test sets
train_orig = training(split) 

train = train_orig %>% 
  select(-c(game_id))



test_orig = testing(split)

test = test_orig %>% 
  select(-c(game_id))

# Check the dimensions of the resulting datasets
dim(train)
dim(test)
```

### Prepare Data for XGBoost
```{r}

# Point Diff

# Create training matrix
pd_train_matrix = xgb.DMatrix(data = as.matrix(train[,1:109]), 
                              label = as.numeric(train$t1_point_diff))

# Create training matrix
pd_test_matrix = xgb.DMatrix(data = as.matrix(test[,1:109]), 
                              label = as.numeric(test$t1_point_diff))




# Total Points

# Create training matrix
pd_train_matrix2 = xgb.DMatrix(data = as.matrix(train[,1:109]), 
                              label = as.numeric(train$total_points))

# Create training matrix
pd_test_matrix2 = xgb.DMatrix(data = as.matrix(test[,1:109]), 
                              label = as.numeric(test$total_points))
```

### Betting Lines Data Prep

```{r}

# just consensus lines
bl_condensed_home = betting_lines %>% 
  filter(provider == 'consensus') %>% 
  # calculate spread, select meaningful cols
  mutate(t1_team = home_team,
         t2_team = away_team,
         t1_score = home_score,
         t2_score = away_score,
         t1_point_diff2 = t1_score - t2_score,
         total_points2 = t1_score + t2_score,
         t1_spread = spread * -1) %>% 
  select(week, t1_team, t2_team, over_under, t1_spread, season)

bl_condensed_away = betting_lines %>% 
  filter(provider == 'consensus') %>% 
  mutate(t2_team = home_team,
         t1_team = away_team,
         t2_score = home_score,
         t1_score = away_score,
         t1_point_diff2 = t1_score - t2_score,
         total_points2 = t1_score + t2_score,
         t1_spread = spread) %>% 
  select(week, t1_team, t2_team, over_under, t1_spread, season)


# combine home and away
bl_condensed = rbind(bl_condensed_away, bl_condensed_home)


# join dfs
bl_joined = left_join(test, bl_condensed, by = c('week', 'season', 't1_team', 't2_team'))

```

<br>

# *Point Diff Modeling*

### Create first model

```{r}

set.seed(596)

bst_1 <- xgboost(data = pd_train_matrix, # Set training data

               

               nrounds = 100, # Set number of rounds

               

               verbose = 1, # 1 - Prints out fit

                print_every_n = 20# Prints out result every 20th iteration

 )
```
```{r}

boost_preds_1 <- predict(bst_1, pd_test_matrix) # Create predictions for xgboost model

pred_dat <- cbind.data.frame(boost_preds_1 , test$t1_point_diff)

rmse(test$t1_point_diff, boost_preds_1)


#pred_dat

```
```{r}

pred_dat_win = pred_dat %>% 
  mutate(actual_win = ifelse(`test$t1_point_diff` > 0, 1, 0)) %>% 
  mutate(pred_win = ifelse(boost_preds_1 > 0, 1, 0))


# Create confusion matrix
conf_matrix <- confusionMatrix(as.factor(pred_dat_win$pred_win),
                                     as.factor(pred_dat_win$actual_win), positive = "1")

# Print confusion matrix and sensitivity
print(conf_matrix)

```

<br>

Tuned model here, see the model_tuning rmd for code on that.

<br>

### Tuned Model 

```{r}
set.seed(844)
bst_final <- xgboost(data = pd_train_matrix, # Set training data
              
        
               
              eta = 0.005, # Set learning rate
                     
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
              
              
              #alpha = 0.1, 
              #lambda = 1.5,
               
              nrounds = 3507 , # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
               
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
              
              eval_metric = "rmse") # Set evaluation metric to use



```

```{r}

boost_preds_final <- predict(bst_final, pd_test_matrix) # Create predictions for xgboost model

pred_dat_final <- cbind.data.frame(boost_preds_final, test$t1_point_diff)

rmse(test$t1_point_diff, boost_preds_final) # print rmse


head(pred_dat_final) # print prediction df

```

```{r}

# analyze predictive ability on wins/losses
pred_dat_win_final =pred_dat_final %>% 
  mutate(actual_win = ifelse(`test$t1_point_diff` > 0, 1, 0)) %>% 
  mutate(pred_win = ifelse(boost_preds_final > 0, 1, 0))


# Create confusion matrix
conf_matrix_final <- confusionMatrix(as.factor(pred_dat_win_final$pred_win),
                                     as.factor(pred_dat_win_final$actual_win), positive = "1")

# Print confusion matrix and sensitivity
print(conf_matrix_final)

```

### At last, let's look at our plot of Actuals vs Predicted Values

```{r}
# combine into df
plot_dat <- cbind.data.frame(test$t1_point_diff,boost_preds_final )
names(plot_dat) <- c("actual", "predicted")

# plot
ggplot(plot_dat, aes(x = actual, y = predicted)) +
  geom_point() +
  geom_smooth()
```


### Variable Importance, Top 10
```{r}
# Extract importance
imp_mat <- xgb.importance(model = bst_final)
# Plot importance (top 10 variables)
xgb.plot.importance(imp_mat, top_n = 10)
```


### Linear Model
```{r}
linear_model = lm(t1_point_diff ~ ., data = train[,c(1:109, 114)])

summary(linear_model)
```


```{r}
linear_pred = predict(linear_model, test[,c(1:109,114)])

rmse(linear_pred, test$t1_point_diff)

linear_dat <- cbind.data.frame(linear_pred, test$t1_point_diff)


```

```{r}
linear_dat_win = linear_dat %>% 
  mutate(actual_win = ifelse(`test$t1_point_diff` > 0, 1, 0)) %>% 
  mutate(pred_win = ifelse(linear_pred > 0, 1, 0))


# Create confusion matrix
conf_matrix <- confusionMatrix(as.factor(linear_dat_win$pred_win),
                                     as.factor(linear_dat_win$actual_win), positive = "1")

# Print confusion matrix and sensitivity
print(conf_matrix)

```




### Spread Model

```{r}


bl_pred = bl_joined %>% 
  mutate(bl_pred_win = ifelse(t1_spread > 0, 1, ifelse(t1_spread < 0, 0, NA))) %>% 
  filter(!is.na(bl_pred_win))




# pred_dat_win_spread = bl_pred %>% 
#   mutate(actual_win = ifelse(`test$t1_point_diff` > 0, 1, 0)) %>% 
#   mutate(pred_win = ifelse(boost_preds_final > 0, 1, 0))


# Create confusion matrix
conf_matrix_spread <- confusionMatrix(as.factor(bl_pred$bl_pred_win),
                                     as.factor(bl_pred$t1_win), positive = "1")

# Print confusion matrix and sensitivity
print(conf_matrix_spread)

```

<br>

# *Total Points Model*


### Optimal Iterations

```{r}
# Use xgb.cv to run cross-validation inside xgboost
set.seed(844)
bst <- xgb.cv(data = pd_train_matrix2, # Set training data
              
              nfold = 5, # Use 5 fold cross-validation
               
              
              eta = 0.005, # Set learning rate
                     
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
                     #.15
                     
                     
              nrounds = 100000, # Set number of rounds
              early_stopping_rounds = 1000, # Prints out result every 20th iteration,
                     
            
              
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
               
              eval_metric = "rmse") # Set evaluation metric to use
```

nrounds = 1111

<br>

### Run Model

```{r}
set.seed(844)
bst_final_tp <- xgboost(data = pd_train_matrix2, # Set training data
              
        
               
              eta = 0.005, # Set learning rate
                     
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
               
              nrounds = 1111 , # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
               
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
              
              eval_metric = "rmse") # Set evaluation metric to use



```


```{r}

boost_preds_final_tp <- predict(bst_final_tp, pd_test_matrix2) # Create predictions for xgboost model

pred_dat_final_tp <- cbind.data.frame(boost_preds_final_tp, test$total_points)

rmse(test$total_points, boost_preds_final_tp)


#pred_dat_final_tp

```

<br>

# *Break Even Analysis*

```{r}

test2 = test
test2$pred_t1_point_diff = boost_preds_final


bl_joined_preds = left_join(test2, bl_condensed, by = c("week", "season", "t1_team", "t2_team"))

bl_joined_preds = bl_joined_preds %>% 
  mutate(take_t1 = ifelse(pred_t1_point_diff > t1_spread, 1, 0)) %>% 
  mutate(taking_spread_won = ifelse(t1_point_diff > t1_spread, 1, 0))


# Create confusion matrix
conf_matrix_against_spread <- confusionMatrix(as.factor(bl_joined_preds$take_t1),
                                     as.factor(bl_joined_preds$taking_spread_won), positive = "1")

# Print confusion matrix and sensitivity
print(conf_matrix_against_spread)




# 52.38 to break even from vig, just missed at .5203

```

<br>

# *Future Predictions*

### Load New Data
```{r}
cfb_data_updated = read.csv("G:/Shared drives/Machine Learning/cfb_project_data_prep_file_updated.csv")[,-1]

betting_lines_updated = read.csv("G:/Shared drives/Machine Learning/betting_lines_file_updated.csv")[,-1]
```


### Filter for this week's games

```{r}

# filter for next week's game
week7 = cfb_data_updated %>% 
  filter(season == 2024 & week == 7 & t1_division == 'fbs' & t2_division == 'fbs')%>% 
  select(-c(t1_division, t2_division)) 

```


### Re-do Data Prep

```{r}

# redo data prep

# treat NAs
model_prepped_orig_w7 = week7 %>% 
  select(-c(completed)) %>% # get rid of completed column
  filter(!is.na(t1_rol_pa_pg_l3) & !is.na(t2_rol_pa_pg_l3)) # get rid of games w/o previous game info data
  

response_holder_w7 = model_prepped_orig_w7 %>% 
  select(c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team, game_id))

model_prepped_omit_w7 = model_prepped_orig_w7 %>% 
  select(-c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team, game_id))




model_prepped_w7 = model_prepped_omit_w7 %>% 
  dummy_cols('t1_conference') %>% 
  dummy_cols('t2_conference') %>% 
  select(-c(t1_conference, t2_conference, season_type, t1_points, t2_points)) %>% 
  mutate(neutral_site = ifelse(neutral_site == TRUE, 1, 0)) %>% 
  mutate(conference_game = ifelse(conference_game == TRUE, 1, 0))
model_prepped_w7$season = response_holder_w7$season
model_prepped_w7$week = response_holder_w7$week
model_prepped_w7$t1_team = response_holder_w7$t1_team 
model_prepped_w7$t2_team = response_holder_w7$t2_team
model_prepped_w7$t1_point_diff = 0
model_prepped_w7$total_points = 0
model_prepped_w7$t1_win = response_holder_w7$t1_win
model_prepped_w7$game_id = response_holder_w7$game_id




# Create training matrix
pd_matrix_w7 = xgb.DMatrix(data = as.matrix(model_prepped_w7[,1:109]), 
                              label = as.numeric(model_prepped_w7$t1_point_diff))

# Create training matrix
pd_matrix2_w7 = xgb.DMatrix(data = as.matrix(model_prepped_w7[,1:109]), 
                              label = as.numeric(model_prepped_w7$total_points))


```

### Use Model to Predict Week 7 Games

```{r}
# Point Diff

boost_preds_final_w7 <- predict(bst_final, pd_matrix_w7) # Create predictions for xgboost model

pred_dat_final_w7 <- cbind.data.frame(model_prepped_w7$t1_team, model_prepped_w7$t2_team, boost_preds_final_w7, model_prepped_w7$t1_point_diff, model_prepped_w7$game_id)


# head of pred df
head(pred_dat_final_w7)

# ND
pred_dat_final_w7 %>% filter(`model_prepped_w7$t1_team` == 'Notre Dame')

```

```{r}
# Total Points

boost_preds_final2_w7 <- predict(bst_final_tp, pd_matrix2_w7) # Create predictions for xgboost model

pred_dat_final2_w7 <- cbind.data.frame(model_prepped_w7$t1_team, model_prepped_w7$t2_team, boost_preds_final2_w7, model_prepped_w7$total_points, model_prepped_w7$game_id)


# final pred df
head(pred_dat_final2_w7)

# ND
pred_dat_final2_w7 %>% filter(`model_prepped_w7$t1_team` == 'Notre Dame')
```

```{r}

# combine point diff and total points dfs
preds_full_w7 = left_join(pred_dat_final_w7, pred_dat_final2_w7,
                         by = c("model_prepped_w7$t1_team", "model_prepped_w7$t2_team",
                                "model_prepped_w7$game_id"))

# modify col names and calculate predicted scores
preds_full_w7 = preds_full_w7 %>% 
  select(-c(`model_prepped_w7$t1_point_diff`, `model_prepped_w7$total_points`)) %>% 
  rename(game_id = `model_prepped_w7$game_id`,
         team1 = `model_prepped_w7$t1_team`,
         team2 = `model_prepped_w7$t2_team`,
         pred_t1_point_diff = boost_preds_final_w7,
         pred_total_points = boost_preds_final2_w7) %>% 
  mutate(pred_t1_score = (pred_total_points / 2) + (pred_t1_point_diff / 2)) %>% 
  mutate(pred_t2_score = pred_total_points - pred_t1_score) %>% 
  mutate(pred_t1_win = ifelse(pred_t1_score > pred_t2_score, 1, 0)) %>% 
  group_by(game_id) %>% 
  filter(row_number() < 2) %>% 
  ungroup() %>% 
  select(-c(game_id))
  

# ND
preds_full_w7 %>% filter(team1 == 'Notre Dame')

# All
preds_full_w7


```




